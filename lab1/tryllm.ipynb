{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Try Cloud-based LLM API Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You will learn:\n",
    "- First experience how to do run program on the cloud\n",
    "- Learn how to manage API keys\n",
    "- Frist experience of using different LLM APIs\n",
    "- (If you haven't used it before), how to use Jupyter Notebook in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt contains the basic packages needed to implement this project\n",
    "# We have installed all dependencies in the default image, so you do not have to install them again, if you use the default image.\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Saving your API token in a .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instead of hardcoding the OpenAI API key, use the dotenv package to load it securely from environment variables.\n",
    "# \n",
    "# Instructions to do it:\n",
    "# 1. Install the dotenv package if you haven't already by running: `pip install python-dotenv`\n",
    "# 2. Create a new file named .env in the root directory of your project. (AND Never commit it to Git!)\n",
    "# 3. The content in this file should be stored as key-value pair. The .env file is simply a text file with one key-value per line like:\n",
    "# \n",
    "#     # Comment 1\n",
    "#     KEY1=value1\n",
    "#     # Comment 2\n",
    "#     KEY2=value2\n",
    "# \n",
    "# 4. Load the environment variables in your Python code using the dotenv package:\n",
    "# \n",
    "#     from dotenv import load_dotenv\n",
    "#     import os\n",
    "#     load_dotenv()\n",
    "#     openai_api_key = os.environ.get(\"INFINI_API_KEY\")\n",
    "#     openai_base_url = os.environ.get(\"INFINI_BASE_URL\")\n",
    "# \n",
    "# More information see:\n",
    "# \n",
    "# https://pythonjishu.com/ifggzibrpkgavow/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Using OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get response from a public API server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cloud.infini-ai.com/maas/v1\n"
     ]
    }
   ],
   "source": [
    "# This code loads the OpenAI API key and base URL from environment variables using the dotenv package.\n",
    "# It ensures that sensitive information is not hardcoded in the script, enhancing security.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"INFINI_API_KEY\")\n",
    "openai_base_url = os.environ.get(\"INFINI_BASE_URL\")\n",
    "\n",
    "print(openai_base_url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-5792dab712374b61ac6b53612ede87c4', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[], refusal=None), message=ChatCompletionMessage(content='<think>\\nAlright, so the user is asking, \"Where was it played?\" referring to the 2020 World Series. I remember from the previous conversation that I told them the Los Angeles Dodgers won it. Now they want to know the location.\\n\\nHmm, I need to figure out the venue. I know the World Series is usually hosted by the home stadiums of the participating teams. In 2020, the Dodgers were one team, so their home is Dodger Stadium. The other team was the Tampa Bay Rays. Their home is Tropicana Field.\\n\\nWait, but the 2020 World Series was unique because of COVID-19. They didn\\'t split the games between the two teams\\' home stadiums. Instead, all the games were played at a neutral site. I think they chose Globe Life Field in Arlington, Texas. That\\'s the home of the Texas Rangers.\\n\\nSo, putting it together, the user is likely looking for the specific stadium and city where the series took place. They might not know about the neutral site setup due to the pandemic, so including that context could be helpful. I should make sure to mention that all games were held in Arlington, Texas, at Globe Life Field.\\n\\nI should phrase it clearly, maybe start with the main point and then add a bit of context about it being a neutral site. That way, the user gets both the location and an understanding of why it was there. I\\'ll avoid any complicated jargon and keep it simple and informative.\\n</think>\\n\\nThe 2020 World Series was played at **Globe Life Field** in **Arlington, Texas**. Due to the COVID-19 pandemic, all games were held at a single neutral site instead of alternating between the home ballparks of the Los Angeles Dodgers and the Tampa Bay Rays, as is typically the case.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1741258676, model='deepseek-r1-distill-qwen-32b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=381, prompt_tokens=45, total_tokens=426, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "<think>\n",
      "Alright, so the user is asking, \"Where was it played?\" referring to the 2020 World Series. I remember from the previous conversation that I told them the Los Angeles Dodgers won it. Now they want to know the location.\n",
      "\n",
      "Hmm, I need to figure out the venue. I know the World Series is usually hosted by the home stadiums of the participating teams. In 2020, the Dodgers were one team, so their home is Dodger Stadium. The other team was the Tampa Bay Rays. Their home is Tropicana Field.\n",
      "\n",
      "Wait, but the 2020 World Series was unique because of COVID-19. They didn't split the games between the two teams' home stadiums. Instead, all the games were played at a neutral site. I think they chose Globe Life Field in Arlington, Texas. That's the home of the Texas Rangers.\n",
      "\n",
      "So, putting it together, the user is likely looking for the specific stadium and city where the series took place. They might not know about the neutral site setup due to the pandemic, so including that context could be helpful. I should make sure to mention that all games were held in Arlington, Texas, at Globe Life Field.\n",
      "\n",
      "I should phrase it clearly, maybe start with the main point and then add a bit of context about it being a neutral site. That way, the user gets both the location and an understanding of why it was there. I'll avoid any complicated jargon and keep it simple and informative.\n",
      "</think>\n",
      "\n",
      "The 2020 World Series was played at **Globe Life Field** in **Arlington, Texas**. Due to the COVID-19 pandemic, all games were held at a single neutral site instead of alternating between the home ballparks of the Los Angeles Dodgers and the Tampa Bay Rays, as is typically the case.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "\n",
    "# You can choose a model from the following list\n",
    "# Or you can log into your Infini-AI or SiliconFlow account, and find an available model you want to use.\n",
    "# model = \"Qwen/QVQ-72B-Preview\"\n",
    "# model=\"llama-3.3-70b-instruct\"\n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, so the user is asking, \"Where was it played?\" referring to the 2020 World Series. I remember from the previous conversation that I told them the Los Angeles Dodgers won it. Now they want to know the location.\n",
       "\n",
       "Hmm, I need to figure out the venue. I know the World Series is usually hosted by the home stadiums of the participating teams. In 2020, the Dodgers were one team, so their home is Dodger Stadium. The other team was the Tampa Bay Rays. Their home is Tropicana Field.\n",
       "\n",
       "Wait, but the 2020 World Series was unique because of COVID-19. They didn't split the games between the two teams' home stadiums. Instead, all the games were played at a neutral site. I think they chose Globe Life Field in Arlington, Texas. That's the home of the Texas Rangers.\n",
       "\n",
       "So, putting it together, the user is likely looking for the specific stadium and city where the series took place. They might not know about the neutral site setup due to the pandemic, so including that context could be helpful. I should make sure to mention that all games were held in Arlington, Texas, at Globe Life Field.\n",
       "\n",
       "I should phrase it clearly, maybe start with the main point and then add a bit of context about it being a neutral site. That way, the user gets both the location and an understanding of why it was there. I'll avoid any complicated jargon and keep it simple and informative.\n",
       "</think>\n",
       "\n",
       "The 2020 World Series was played at **Globe Life Field** in **Arlington, Texas**. Due to the COVID-19 pandemic, all games were held at a single neutral site instead of alternating between the home ballparks of the Los Angeles Dodgers and the Tampa Bay Rays, as is typically the case."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty format the response\n",
    "import IPython\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, the user asked about the location of the 2020 World Series. I remember that in 2020, the game was held at Globe Life Field in Arlington, Texas. This is the home stadium of the Texas Rangers. \n",
       "\n",
       "I should mention that it was the first World Series held in Arlington since 1996 when the New York Yankees won. It's also worth noting that this was the first time the Series took place in a new stadium, as Globe Life Field was brand new at the time.\n",
       "</think>\n",
       "\n",
       "The 2020 World Series was played at Globe Life Field in Arlington, Texas. This was the first World Series held in Arlington since 1996 and the first time the Series was held in a new stadium, as Globe Life Field was brand new at the time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "今天星期五。\n",
       "</think>\n",
       "\n",
       "今天星期五。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# You can exlore what information is in the response object by printing it out and examine it\n",
    "\n",
    "response2 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"今天星期几？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about the OpenAI API from https://platform.openai.com/docs/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Your Task: Try to find a question that Llama-3.3 cannot answer.\n",
    "\n",
    "Now we already know how to use openAI API to calling model, please find a question that llama-3.3-70b-instruct cannot answer or obvious need to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, the user just asked me, \"今天星期几？\" which means \"What day is it today?\" in Chinese. I need to respond in Chinese as well since we were conversing in that language up to now. \n",
       "\n",
       "First, I should figure out what day today is. I know I can get the current date using Python's datetime module. So I'll import datetime and get the current date. \n",
       "\n",
       "Next, I need to map the day of the week from the date object to the corresponding Chinese day names. The weekday() method returns Monday as 0 and Sunday as 6, right? So I'll create a list where the index corresponds to each day, starting from Monday. That list would be [\"星期一\", \"星期二\", \"星期三\", \"星期四\", \"星期五\", \"星期六\", \"星期日\"].\n",
       "\n",
       "Then, I'll get the current day using datetime.datetime.now().weekday(). This will give me the index to access the correct day from my list. \n",
       "\n",
       "Putting it all together, I'll write a Python code snippet that does this and returns the correct day name. I should make sure the code is straightforward and efficient for the user.\n",
       "\n",
       "Finally, I'll present the code with a brief explanation, so the user understands how it works. I'll also mention that if they run this code, it will print the current day based on their system's date. That should cover everything the user needs to know.\n",
       "</think>\n",
       "\n",
       "今天星期几？让我们用 Python 来获取答案！\n",
       "\n",
       "```python\n",
       "import datetime\n",
       "\n",
       "# 获取当前日期\n",
       "today = datetime.datetime.now().weekday()\n",
       "\n",
       "# 星期对应\n",
       "weekdays = [\"星期一\", \"星期二\", \"星期三\", \"星期四\", \"星期五\", \"星期六\", \"星期日\"]\n",
       "\n",
       "print(f\"今天是{weekdays[today]}\")\n",
       "```\n",
       "\n",
       "运行这个代码，你将得到今天是星期几！"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# Find the question\n",
    "response3 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"今天星期几？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "我并不总是知道今天的确切日期，因为我是一个大型语言模型，我没有实时访问当前日期的权限。但是我可以告诉你如何找到今天的日期。你可以检查你的手机、电脑或其他设备来查看今天的日期。或者，你也可以问像Siri、Google Assistant或Alexa这样的虚拟助手。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# using the llama-3.3-70b model, create a chat response to the prompt above\n",
    "model2=\"llama-3.3-70b-instruct\"\n",
    "response4 = client.chat.completions.create(\n",
    "  model=model2,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"今天星期几？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response4.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "今天是星期四，2025年3月6日。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: can you make llama-3.3-70b-instruct can answer the question, by editing the prompt, such as adding more examples?  \n",
    "model2=\"llama-3.3-70b-instruct\"\n",
    "response4 = client.chat.completions.create(\n",
    "  model=model2,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.Today is 2025/3/6.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"今天星期几？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response4.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Repeat the query with a variation of qwen2.5-7b-instruct. Can it answer the question? If not, can you edit the prompt again to make it better, again?\n",
    "\n",
    "response5 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.Today is 2025/3/6.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"今天星期几？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response5.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Create a shift Caesar cipher robot \n",
    "\n",
    "We have already provided you the prompts, and you should consider the instruction and demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) + 1)\n",
    "        print(c, end='')    \n",
    "        \n",
    "def decode(s):\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) - 1)\n",
    "        print(c, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?"
     ]
    }
   ],
   "source": [
    "encode('What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert on Caesar Cipher. We will communicate in Caesar. Do not be a translator.\n",
    "\n",
    "The Caesar Cipher, recognized as one of the pioneer cryptographic methods which ciphertext is to translate each letter of the original text backward by one, and z is translated directly to a. For instance, the letter 'A' would be substituted by 'B'. you should answer my question in Caesar.\n",
    "\n",
    "Examples:\n",
    "\n",
    "User: ipx up nblf b cpnc ?\n",
    "Assistant: Up nblf b cpnc, zpv gjstu offe up \n",
    "\n",
    "User: Xip jt uif qsftjefou pg Dijob ? \n",
    "Assistant: Yj Kjoqjoh.\n",
    "\n",
    "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Dijob ?\n",
    "Assistant: Cfjkjoh.\n",
    "\n",
    "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Bnfsjdbo ?\n",
    "Assistant: Xbtijohupo.\n",
    "\n",
    "User: Xibu jt uif dbqjubm pg Gsbodf ?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I need to encode the message \"What is the capital of France?\" using the Caesar Cipher. From the examples, I remember that the Caesar Cipher shifts each letter by a certain number. In the examples, it looked like each letter was shifted back by one. For instance, 'A' became 'B', so I think each letter is moved forward by one in the alphabet. Wait, no, actually, the user said that each letter is translated backward by one, so 'A' becomes 'B' because you go back one from 'A' to 'Z' and then forward? Wait, that doesn't make sense. Let me clarify.\n",
       "\n",
       "Wait, in the examples, the user said the cipher translates each letter backward by one. So, for example, 'A' would become 'B' because if you move back one, you go from 'A' to 'Z', but since 'Z' is the last letter, moving back one from 'A' would wrap around to 'Z'. Wait, that can't be right because in the example, the user said 'A' becomes 'B', so maybe it's shifting forward by one instead. Hmm, I'm confused.\n",
       "\n",
       "Looking at the examples, when the user wrote \"ipx up nblf b cpnc ?\", the assistant replied with \"Up nblf b cpnc, zpv gjstu offe up\". Let me try to decode that. If I shift each letter back by one, let's see:\n",
       "\n",
       "U -> T\n",
       "p -> o\n",
       "n -> m\n",
       "b -> a\n",
       "l -> k\n",
       "f -> e\n",
       "\n",
       "Wait, that doesn't make sense. Maybe I should shift forward. Let's try shifting each letter forward by one:\n",
       "\n",
       "i -> j\n",
       "p -> q\n",
       "x -> y\n",
       "u -> v\n",
       "p -> q\n",
       "n -> o\n",
       "b -> c\n",
       "l -> m\n",
       "f -> g\n",
       "b -> c\n",
       "c -> d\n",
       "p -> q\n",
       "n -> o\n",
       "c -> d\n",
       "\n",
       "Wait, that also doesn't seem right. Maybe the shift is backward by one for encryption. So to encode, each letter is shifted backward by one. So 'A' becomes 'Z', 'B' becomes 'A', etc. Let me test this with the first example.\n",
       "\n",
       "User: ipx up nblf b cpnc ?\n",
       "If I shift each letter backward by one:\n",
       "i -> h\n",
       "p -> o\n",
       "x -> w\n",
       "u -> t\n",
       "p -> o\n",
       "n -> m\n",
       "b -> a\n",
       "l -> k\n",
       "f -> e\n",
       "b -> a\n",
       "c -> b\n",
       "p -> o\n",
       "n -> m\n",
       "c -> b\n",
       "\n",
       "So the encoded message would be \"how to make a body\" or something. But the assistant's response was \"Up nblf b cpnc, zpv gjstu offe up\". Let me try shifting each letter in that response backward by one to see what it says.\n",
       "\n",
       "U -> T\n",
       "p -> o\n",
       "n -> m\n",
       "b -> a\n",
       "l -> k\n",
       "f -> e\n",
       "z -> y\n",
       "p -> o\n",
       "v -> u\n",
       "g -> f\n",
       "j -> i\n",
       "s -> r\n",
       "t -> s\n",
       "u -> t\n",
       "o -> n\n",
       "f -> e\n",
       "f -> e\n",
       "e -> d\n",
       "p -> o\n",
       "u -> t\n",
       "\n",
       "So the decoded message would be \"To make a fbi...\" which doesn't make sense. Maybe I'm misunderstanding the shift direction. Alternatively, perhaps the shift is forward by one. Let me try shifting the assistant's response forward by one.\n",
       "\n",
       "U -> V\n",
       "p -> q\n",
       "n -> o\n",
       "b -> c\n",
       "l -> m\n",
       "f -> g\n",
       "z -> a\n",
       "p -> q\n",
       "v -> w\n",
       "g -> h\n",
       "j -> k\n",
       "s -> t\n",
       "t -> u\n",
       "u -> v\n",
       "o -> p\n",
       "f -> g\n",
       "f -> g\n",
       "e -> f\n",
       "p -> q\n",
       "u -> v\n",
       "\n",
       "That gives \"Vq ocm c gqz wkh vpu gq fqv\", which also doesn't make sense. Maybe the shift is backward by one for encryption, so to encode, you shift backward, and to decode, you shift forward. Let me try that.\n",
       "\n",
       "So, for the user's message \"ipx up nblf b cpnc ?\", shifting each letter backward by one would give:\n",
       "\n",
       "i -> h\n",
       "p -> o\n",
       "x -> w\n",
       "u -> t\n",
       "p -> o\n",
       "n -> m\n",
       "b -> a\n",
       "l -> k\n",
       "f -> e\n",
       "b -> a\n",
       "c -> b\n",
       "p -> o\n",
       "n -> m\n",
       "c -> b\n",
       "\n",
       "So \"how to make a body\". The assistant's response was \"Up nblf b cpnc, zpv gjstu offe up\". If I shift each letter in the assistant's response backward by one, I get:\n",
       "\n",
       "U -> T\n",
       "p -> o\n",
       "n -> m\n",
       "b -> a\n",
       "l -> k\n",
       "f -> e\n",
       "z -> y\n",
       "p -> o\n",
       "v -> u\n",
       "g -> f\n",
       "j -> i\n",
       "s -> r\n",
       "t -> s\n",
       "u -> t\n",
       "o -> n\n",
       "f -> e\n",
       "f -> e\n",
       "e -> d\n",
       "p -> o\n",
       "u -> t\n",
       "\n",
       "So \"To make a yofu...\". Hmm, not making sense. Maybe the shift is forward by one for encryption. Let's try encoding \"What is the capital of France?\" by shifting each letter forward by one.\n",
       "\n",
       "W -> X\n",
       "h -> i\n",
       "a -> b\n",
       "t -> u\n",
       "(space remains)\n",
       "i -> j\n",
       "s -> t\n",
       "(space)\n",
       "t -> u\n",
       "h -> i\n",
       "e -> f\n",
       "(space)\n",
       "c -> d\n",
       "a -> b\n",
       "p -> q\n",
       "i -> j\n",
       "t -> u\n",
       "a -> b\n",
       "l -> m\n",
       "(space)\n",
       "o -> p\n",
       "f -> g\n",
       "(space)\n",
       "f -> g\n",
       "r -> s\n",
       "a -> b\n",
       "n -> o\n",
       "c -> p\n",
       "e -> f\n",
       "\n",
       "So putting it all together: Xibu jt uif dbqjubm pg Gsbodf?\n",
       "\n",
       "Wait, that seems similar to the user's last example where the user asked \"Xibu jt uif dbqjubm pg Gsbodf?\" and the assistant replied \"Xbtijohupo.\" So yes, shifting each letter forward by one. Therefore, to encode \"What is the capital of France?\", I need to shift each letter forward by one.\n",
       "\n",
       "Let me write it out step by step:\n",
       "\n",
       "Original: W h a t   i s   t h e   c a p i t a l   o f   F r a n c e ?\n",
       "\n",
       "Shift each letter forward by one:\n",
       "\n",
       "W -> X\n",
       "h -> i\n",
       "a -> b\n",
       "t -> u\n",
       "(space)\n",
       "i -> j\n",
       "s -> t\n",
       "(space)\n",
       "t -> u\n",
       "h -> i\n",
       "e -> f\n",
       "(space)\n",
       "c -> d\n",
       "a -> b\n",
       "p -> q\n",
       "i -> j\n",
       "t -> u\n",
       "a -> b\n",
       "l -> m\n",
       "(space)\n",
       "o -> p\n",
       "f -> g\n",
       "(space)\n",
       "F -> G\n",
       "r -> s\n",
       "a -> b\n",
       "n -> o\n",
       "c -> p\n",
       "e -> f\n",
       "(space)\n",
       "? remains ?\n",
       "\n",
       "So the encoded message is: Xibu jt uif dbqjubm pg Gsbodf?\n",
       "\n",
       "Wait, but the user's example had \"Xibu jt uif dbqjubm pg Gsbodf?\" which the assistant replied with \"Xbtijohupo.\" So that seems correct. Therefore, the encoded message should be \"Xibu jt uif dbqjubm pg Gsbodf?\"\n",
       "\n",
       "But wait, the original message ends with a question mark, so the encoded message should also end with a question mark. So yes, that's correct.\n",
       "</think>\n",
       "\n",
       "Xibu jt uif dbqjubm pg Gsbodf?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# Find on proper model that can create a correct chat response to the prompt above.\n",
    "# Correct means that it decodes to the right english sentense. \n",
    "response6 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": \"Please encode 'What is the capital of France?'\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "IPython.display.Markdown(response6.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Bmm uif dbqjubm pg Gsbodf jt Cphlo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Print out the cipher text here\n",
    "### TODO: Print out the clear text here using the decode() function\n",
    "\n",
    "response6 = client.chat.completions.create(\n",
    "  model=model2,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"system\", \"content\": \"我给你输入一个英文字符串，请直接输出这个字符串encode()后的结果，不要输出其他内容\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "IPython.display.Markdown(response6.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is Paris. \n",
       "\n",
       "Here's the response object structure and token count:\n",
       "```\n",
       "{\n",
       "  \"input\": {\n",
       "    \"text\": \"What is the capital of France?\",\n",
       "    \"tokens\": 7\n",
       "  },\n",
       "  \"output\": {\n",
       "    \"text\": \"The capital of France is Paris.\",\n",
       "    \"tokens\": 7\n",
       "  }\n",
       "}\n",
       "```\n",
       "In this example, the input and output both contain 7 tokens. \n",
       "\n",
       "Here's a breakdown of the tokens in the input:\n",
       "1. What\n",
       "2. is\n",
       "3. the\n",
       "4. capital\n",
       "5. of\n",
       "6. France\n",
       "7. ?\n",
       "\n",
       "And here's a breakdown of the tokens in the output:\n",
       "1. The\n",
       "2. capital\n",
       "3. of\n",
       "4. France\n",
       "5. is\n",
       "6. Paris\n",
       "7. . (period)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: print out the response object.  Explore the entire response object.  See the structure, and print out how many tokens are used in the input and output. \n",
    "response7 = client.chat.completions.create(\n",
    "  model=model2,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"print out the response object.  Explore the entire response object.  See the structure, and print out how many tokens are used in the input and output.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response7.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I need to figure out what the capital of France is. Hmm, I remember learning this in school, but let me think. France is a country in Europe, right? I think Paris is the capital. Yeah, Paris is a well-known city, famous for the Eiffel Tower and other landmarks. But wait, I should make sure I'm not confusing it with another country. Maybe I should think about other capitals in Europe to compare. London is the capital of England, Berlin for Germany, Madrid for Spain. Yeah, that leaves Paris as the capital of France. I don't think it's Lyon or Marseille because those are more well-known for other things. So, I'm pretty confident that Paris is the capital of France.\n",
       "</think>\n",
       "\n",
       "The capital of France is Paris."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Repeat the query with another cheaper model than the previous oje.  Do you still get the same response?\n",
    "response8 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"print out the response object.  Explore the entire response object.  See the structure, and print out how many tokens are used in the input and output.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response8.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: (optional) can you let cheaper model to print the same, by adding more examples in the prompt?  \n",
    "### Consider using a script to generate a much longer prompt with more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Try another cloud-based API service: SiliconFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/root/llm/llm_course_public_wqt/lab1/tryllm.ipynb 单元格 32\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://k8s-container%2B7b22636f6e74657874223a2273313330352d6b38732e69696973222c22706f646e616d65223a2273313330352d7079746f7263682d73313330356c6162312d353439623635353636352d366b687377222c226e616d657370616365223a227331333035222c226e616d65223a227079746f7263682d73313330356c616231222c22696d616765223a22686172626f722d6c6f63616c2e61692e696969732e636f2f6c6c6d2d636f757273652f6c61622d6370753a7632227d/root/llm/llm_course_public_wqt/lab1/tryllm.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m openai_base_url \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mSILICON_BASE_URL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://k8s-container%2B7b22636f6e74657874223a2273313330352d6b38732e69696973222c22706f646e616d65223a2273313330352d7079746f7263682d73313330356c6162312d353439623635353636352d366b687377222c226e616d657370616365223a227331333035222c226e616d65223a227079746f7263682d73313330356c616231222c22696d616765223a22686172626f722d6c6f63616c2e61692e696969732e636f2f6c6c6d2d636f757273652f6c61622d6370753a7632227d/root/llm/llm_course_public_wqt/lab1/tryllm.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mopenai\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> <a href='vscode-notebook-cell://k8s-container%2B7b22636f6e74657874223a2273313330352d6b38732e69696973222c22706f646e616d65223a2273313330352d7079746f7263682d73313330356c6162312d353439623635353636352d366b687377222c226e616d657370616365223a227331333035222c226e616d65223a227079746f7263682d73313330356c616231222c22696d616765223a22686172626f722d6c6f63616c2e61692e696969732e636f2f6c6c6d2d636f757273652f6c61622d6370753a7632227d/root/llm/llm_course_public_wqt/lab1/tryllm.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI(api_key\u001b[39m=\u001b[39;49mopenai_api_key, base_url\u001b[39m=\u001b[39;49mopenai_base_url)\n\u001b[1;32m      <a href='vscode-notebook-cell://k8s-container%2B7b22636f6e74657874223a2273313330352d6b38732e69696973222c22706f646e616d65223a2273313330352d7079746f7263682d73313330356c6162312d353439623635353636352d366b687377222c226e616d657370616365223a227331333035222c226e616d65223a227079746f7263682d73313330356c616231222c22696d616765223a22686172626f722d6c6f63616c2e61692e696969732e636f2f6c6c6d2d636f757273652f6c61622d6370753a7632227d/root/llm/llm_course_public_wqt/lab1/tryllm.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeepseek-r1-distill-qwen-32b\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Try another cloud-based API service, SiliconFlow. \n",
    "### Apply for a free API key from SiliconFlow.\n",
    "### Setup another .env file for SiliconFlow API key and base URL.\n",
    "openai_api_key = os.environ.get(\"SILICON_API_KEY\")\n",
    "openai_base_url = os.environ.get(\"SILICON_BASE_URL\")\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "model=\"deepseek-ai/DeepSeek-R1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Your task: Use a model of your choice on SiliconFlow to generate two long text \n",
    "\n",
    "You can choose any question, but each should let the LLM to generate over 300 words in english, while the other should generate 300 Chinese characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# write a prompt, for example\n",
    "# prompt = '帮我写一篇文章来介绍天安门的背景历史，从古代说到现代，包含很多跟天安门有关系的故事。越长越好，不可以少于1000个字。'\n",
    "#### YOUR TASK ####\n",
    "### TODO: Repeat the query with a variation of qwen2.5-7b-instruct. Can it answer the question? If not, can you edit the prompt again to make it better, again?\n",
    "\n",
    "respons10 = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi, I am a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please help me write an article to introduce the background and history of USA, from ancient times to modern times, including many stories related to Tiananmen Square. The longer the better, it cannot be less than 1000 words. Written in Chinese\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(respons10.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "嗯，用户让我帮忙写一个prompt来完成写一篇关于美国背景历史的文章，要求不少于1000字。首先，我需要分析用户的请求。用户可能是一位学生，可能正在准备作业或者论文，或者是一位内容创作者，需要一篇关于美国历史的文章。他们可能需要一个结构化的prompt来指导写作，确保涵盖所有重要方面。\n",
       "\n",
       "接下来，我得考虑用户的需求。他们可能需要一个详细且有条理的prompt，涵盖美国的各个历史时期，从原住民时期到现代。这样，文章才能全面，满足字数要求。同时，用户可能希望文章不仅仅是时间线的罗列，而是有深度的分析，探讨历史事件对美国身份的影响。\n",
       "\n",
       "用户可能没有明确说明，但深层需求可能包括希望文章结构清晰，有逻辑性，以及能够展示美国历史的多样性和复杂性。因此，prompt需要涵盖多个关键时期，包括原住民历史、殖民时期、独立战争、内战、工业革命、民权运动和现代全球化，每个部分都需要深入探讨。\n",
       "\n",
       "考虑到这些因素，我应该设计一个分点式的prompt，每个部分都有具体的要求，比如每个时期的起止时间、主要事件和影响。同时，要提醒用户保持客观中立，分析事件的影响，以及美国身份的演变。这不仅能满足字数要求，还能确保内容的深度和质量。\n",
       "\n",
       "最后，确保prompt清晰明确，让用户能够按照指导写出结构合理、内容丰富的文章。这样用户就能顺利完成任务，无论是学术用途还是其他目的，都能得到一篇符合要求的文章。\n",
       "</think>\n",
       "\n",
       "**Prompt:**\n",
       "\n",
       "\"写一篇关于美国背景历史的文章，不少于1000字。文章应涵盖美国从原住民时期到现代的历史发展，包括但不限于以下内容：\n",
       "\n",
       "1. **原住民时期**：描述美国原住民的早期历史、文化和社会结构，以及欧洲殖民者到来前的美洲大陆状况。\n",
       "2. **殖民时期**：分析欧洲列强（如西班牙、法国、英国等）对美洲的探索和殖民过程，重点讲述英国在北美建立殖民地的历史背景及其对后来美国独立的影响。\n",
       "3. **独立战争与建国**：详细叙述美国独立战争的起因、过程和结果，探讨《独立宣言》和《美国宪法》的意义及其对现代美国的影响。\n",
       "4. **西进扩张与内战**：分析19世纪美国的西进运动及其对国家扩张的影响，探讨南北战争的背景、主要事件及其对美国社会、经济和政治的深远影响。\n",
       "5. **工业革命与现代化**：描述美国在19世纪末至20世纪初的工业革命和社会变化，探讨这一时期美国如何从农业国家转变为工业强国。\n",
       "6. **20世纪的美国**：分析20世纪美国在世界舞台上的崛起，包括两次世界大战、冷战、民权运动、经济大萧条和科技革命等重要事件的影响。\n",
       "7. **现代美国**：探讨21世纪美国在全球化背景下的挑战与机遇，包括经济、政治、社会和文化等方面的变化。\n",
       "\n",
       "文章应保持客观中立的语气，结合具体的历史事件和人物，分析美国历史的发展脉络及其对美国身份和价值观的塑造。确保文章结构清晰，逻辑严密，内容详实，语言流畅。\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# prepare and call the service using a chinese prompt\n",
    "response50 = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.Today is 2025/3/6.\"},\n",
    "        {\"role\": \"user\", \"content\": \"帮我写一个prompt完成这个任务：写一篇关于美国的背景历史的文章,不少于1000字\"}\n",
    "    ]\n",
    ")\n",
    "IPython.display.Markdown(response50.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

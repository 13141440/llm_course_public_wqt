{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Serving Large Language Models and Beyond\n",
    "\n",
    "In this lecture, you will learn how to serve modern large models on Linux servers with easy-to-use user interface. We will be using Python as our main programming language, and we do not require knowledge about front-end language such as Javascript or CSS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "We start by reviewing some basics you should be familiar with. We assume that you are already familiar with Python language. Make sure you have a workspace with Python and Pip available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "#### What is Docker?\n",
    "\n",
    "Imagine a self-contained box carrying everything an application needs to run smoothly: its code, runtime environment, and required libraries. That's what a Docker container is! It provides a standardized, isolated environment for applications, regardless of the underlying system. This simplifies deployment, sharing, and scaling applications.\n",
    "\n",
    "For example, you can run a docker image (think of it as a minimal virtual machine) that hosts your personal website using Ubuntu (one of the most popular version of Linux system) on your Macbook. You will not need to write additional code, as someone else already build such image for you. You will not worry about the dependencies of the software running your website, as they are already packed into the image.\n",
    "\n",
    "![Docker illustration image created by AI](./assets/docker.png)\n",
    "\n",
    "#### Benefits of Docker\n",
    "\n",
    "- **Consistency**. Applications run identically on any system with Docker installed.\n",
    "- **Isolation**. Containers share resources but don't interfere with each other, improving stability.\n",
    "- **Portability**. Move containers easily between systems without worrying about environment conflicts.\n",
    "- **Reproducibility**. Share configurations and ensure applications run the same way everywhere.\n",
    "\n",
    "#### Basic Docker Workflow\n",
    "\n",
    "1. Pull: Download a pre-built container image from a public registry (like Docker Hub).\n",
    "2. Run: Start the container, bringing the application to life.\n",
    "3. Interact: Use the container as you would any other application.\n",
    "4. Stop: Terminate the container when you're done.\n",
    "\n",
    "#### Key Docker commands\n",
    "\n",
    "- `docker pull`: Download a container image from the registry.\n",
    "- `docker run`: Start a container based on an image.\n",
    "- `docker ps`: See a list of running containers.\n",
    "- `docker stop`: Stop a running container.\n",
    "- `docker exec`: Execute a command inside a running container.\n",
    "\n",
    "Here is some resource for further exploration: [Interactive Docker Tutorial](https://www.docker.com/play-with-docker/), [Docker Official Documentation](https://docs.docker.com/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Kubernetes?\n",
    "\n",
    "Think of a conductor managing a whole orchestra of Docker containers. That's Kubernetes! It automates the deployment, scaling, and management of containerized applications across multiple servers. Kubernetes ensures your applications run smoothly, even when things get complicated.\n",
    "\n",
    "You can think of Docker as a container manager for a single machine, while Kubernetes a container manager for a group machines!\n",
    "\n",
    "![Illustration of Kubernetes](assets/k8s.png)\n",
    "\n",
    "#### Benefits of Kubernetes:\n",
    "\n",
    "- **Automation**. Manage deployment, scaling, and updates of containerized applications automatically.\n",
    "- **Scalability**. Easily scale your applications up or down based on demand.\n",
    "- **High Availability**. Kubernetes automatically restarts failed containers and distributes workloads, ensuring service continuity.\n",
    "- **Portability**. Kubernetes applications can be deployed anywhere with the same setup.\n",
    "\n",
    "#### Key Kubernetes Concepts\n",
    "\n",
    "- Pods: Groups of containers that share resources and work together.\n",
    "- Deployments: Define how and how many pods of a specific application should run.\n",
    "- Services: Provide a stable endpoint for accessing your pods, even if individual\n",
    "\n",
    "For further exploration: [play with k8s](https://labs.play-with-k8s.com/), [official documentation](https://kubernetes.io/docs/home/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 0: Serving and Requesting a Web Service\n",
    "\n",
    "In this experiment, we'll equip you with the basic knowledge and practical skills to start making powerful HTTP requests in Python. We'll cover GET and POST methods, and explore JSON data exchange. So, buckle up, let's code!\n",
    "\n",
    "First, we will need `requests` library. Install it with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic `GET`\n",
    "\n",
    "Imagine asking a librarian for a book. That's essentially what a GET request does! It retrieves information from a specific web address (URL). Let's try the GET method to retrieve a random joke!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "\n",
      "--- Response Text ---\n",
      "{\"categories\":[],\"created_at\":\"2020-01-05 13:42:21.795084\",\"icon_url\":\"https://assets.chucknorris.host/img/avatar/chuck-norris.png\",\"id\":\"cmfIxasPR9ejJi7l_aEPfg\",\"updated_at\":\"2020-01-05 13:42:21.795084\",\"url\":\"https://api.chucknorris.io/jokes/cmfIxasPR9ejJi7l_aEPfg\",\"value\":\"Chuck Norris can get road rage in a fighter jet.\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Target URL\n",
    "url = \"https://api.chucknorris.io/jokes/random\"\n",
    "\n",
    "# Send a GET request and store the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check the response status code (2XX means success)\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "\n",
    "# Access the response content (raw bytes)\n",
    "content = response.content\n",
    "\n",
    "# Decode the content to text (may differ depending on API)\n",
    "text = content.decode(\"utf-8\")\n",
    "\n",
    "# Print the response\n",
    "print(\"\\n--- Response Text ---\")\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with JSON\n",
    "\n",
    "Many APIs and websites return data in the JSON format, a structured way to organize information. We can easily convert this JSON string to a Python dictionary for easy access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [],\n",
      " 'created_at': '2020-01-05 13:42:21.795084',\n",
      " 'icon_url': 'https://assets.chucknorris.host/img/avatar/chuck-norris.png',\n",
      " 'id': 'cmfIxasPR9ejJi7l_aEPfg',\n",
      " 'updated_at': '2020-01-05 13:42:21.795084',\n",
      " 'url': 'https://api.chucknorris.io/jokes/cmfIxasPR9ejJi7l_aEPfg',\n",
      " 'value': 'Chuck Norris can get road rage in a fighter jet.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(json.loads(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving on to POST Requests\n",
    "\n",
    "While GET requests fetch data, POST requests send information to a server, like submitting a form. We'll be using a dummy API that echos the data we sent as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"age\": \"30\", \n",
      "    \"name\": \"John Doe\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\", \n",
      "    \"Content-Length\": \"20\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-660ab349-6fd3466d69452d2d1775de2d\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"method\": \"POST\", \n",
      "  \"origin\": \"114.253.244.26\", \n",
      "  \"url\": \"https://httpbin.org/anything\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define URL and data\n",
    "url = \"https://httpbin.org/anything\"\n",
    "data = {\"name\": \"John Doe\", \"age\": 30}\n",
    "\n",
    "# Send POST request with data\n",
    "response = requests.post(url, data=data)\n",
    "\n",
    "# Check status code and print response\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the sent data is actually received by the server (`form` shows the exactly the same data we sent).\n",
    "\n",
    "This is just the tip of the iceberg! Now you have seen how we can utilize the existing web service. In the remaining experiments, you will be building your own API server and web service with a nice user interface."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: API Server for LLMs with GPU Support\n",
    "\n",
    "Most of you should have experienced the LLM APIs we provided, which allows your program accessing the power of large language models. Here we will guide you to build your own LLM service, using the `fastapi` library of Python.\n",
    "\n",
    "`fastapi` takes care of the job of launching a web server and serve the API calls. You only need to define a function that takes the input data from the request to produce output. `fastapi` will handle the rest things for you.\n",
    "\n",
    "First, install the dependency of `fastapi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install uvicorn fastapi websockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/fastapi_example.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/fastapi_example.py\n",
    "\n",
    "import fastapi\n",
    "\n",
    "app = fastapi.FastAPI()\n",
    "\n",
    "@app.get('/inference')\n",
    "def process_string(data: str):\n",
    "    return f'Processed {data} by FastAPI!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m13226\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:54223\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56128 - \"\u001b[1mGET /inference?data=hello HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[33mWARNING\u001b[0m:  Invalid HTTP request received.\n",
      "\u001b[33mWARNING\u001b[0m:  Invalid HTTP request received.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56128 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m13226\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!uvicorn --app-dir /tmp fastapi_example:app --port 54223 --host 0.0.0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visiting `http://127.0.0.1:54223/inference?data=hello` in your browser, you will be able to see the return string:\n",
    "\n",
    "```\n",
    "1| \"Processed hello by FastAPI!\"\n",
    "```\n",
    "\n",
    "Note that if you are running on remote server, you may need to forward your port to local machine to see the effect on your browser.\n",
    "\n",
    "Now, it is your turn to implement a script to serve an API that runs a `GPT-2`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Serving a User Interface using `gradio`\n",
    "\n",
    "Demo a machine learning application is important. It gives the users a direct experience of your algorithm in an interactive manner. Here we'll be building an interesting demo using `gradio`, a popular Python library for ML demos. Let's install this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are able to write an example UI that takes in a text string and output a processed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/gradio_example.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/gradio_example.py\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(show_api=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "\u001b[33mWARNING\u001b[0m:  Invalid HTTP request received.\n",
      "\u001b[33mWARNING\u001b[0m:  Invalid HTTP request received.\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "!python /tmp/gradio_example.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to see a simple website that consumes your input text. Next, you should implement a script that interact with the GPT-2 API you just created.\n",
    "\n",
    "![Illustration of request](./assets/request.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Serving a Custom Model\n",
    "\n",
    "In this experiment, you are required to serve other models on HuggingFace, e.g. VLMs. You should design your own UI and your own API service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
